# 手势控制粒子特效 (MediaPipe Particle)

这是一个基于 Web 前端技术开发的互动视觉项目，利用 **HTML5 Canvas** 实现高性能粒子系统，并结合 **Google MediaPipe Hands** 实现实时的手势识别控制。

用户可以通过摄像头进行手势交互，控制数万个粒子的聚合与消散，甚至可以将粒子聚合成自定义上传的图片形状。

## ✨ 功能特性

- **高性能粒子系统**：支持渲染 30,000+ 个 3D 粒子，具备流畅的物理运动效果（弹簧物理、空气阻力）。
- **AI 手势识别**：集成 MediaPipe Hands 模型，无需后端服务，完全在浏览器端进行实时的手部关键点检测。
- **互动控制**：
  - ✊ **握拳**：粒子聚合成目标形状（默认球体或自定义图片）。
  - 🖐 **张手**：粒子受到斥力瞬间炸开并四散漂浮。
- **自定义图片生成**：支持上传本地图片，算法自动采样像素点，将粒子重组为图片画面。
- **视觉特效**：
  - 3D 透视投影与旋转。
  - 粒子流光与呼吸灯效果。
  - 背景动态雪花。
  - 右下角实时手势反馈与骨架可视化。

## 🛠 技术栈

- **核心语言**: HTML5, CSS3, JavaScript (ES6+)
- **渲染引擎**: HTML5 Canvas API (2D Context)
- **AI 模型**: [MediaPipe Hands](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker) (via CDN)
- **依赖库**:
  - `@mediapipe/camera_utils`
  - `@mediapipe/control_utils`
  - `@mediapipe/drawing_utils`
  - `@mediapipe/hands`

## 🚀 快速开始

### 方式一：直接打开

由于项目不依赖复杂的构建工具（如 Webpack/Vite），通过双击 `index.html` 在浏览器中打开即可运行（部分浏览器可能会因安全策略限制摄像头访问，建议使用方式二）。

### 方式二：本地服务器（推荐）

为了确保摄像头权限和文件读取功能正常，建议使用本地静态服务器运行。

如果你安装了 VS Code：

1.  安装 **Live Server** 插件。
2.  在 VS Code 中打开项目文件夹。
3.  右键 `index.html` 选择 "Open with Live Server"。

如果你安装了 Node.js 或 Python：

```bash
# Python 3
python -m http.server 8000

# Node.js (http-server)
npx http-server .
```

然后在浏览器访问 `http://localhost:8000`。

## 📖 操作指南

1.  **授权摄像头**：首次打开页面时，浏览器会询问摄像头权限，请点击“允许”。
2.  **等待初始化**：页面加载模型需要几秒钟，状态栏会显示进度。
3.  **手势控制**：
    - 将手掌面向摄像头。
    - 观察右下角的小窗口，确保绿色的手部骨架已正确识别。
    - **握紧拳头**：观察粒子聚合成形。
    - **张开五指**：观察粒子被打散。
4.  **上传图片**：
    - 点击屏幕上方的 "📁 上传图片生成粒子" 按钮。
    - 选择一张清晰的图片（建议背景简单、主体突出）。
    - 再次做出 **握拳** 手势，粒子将组成你的图片内容。

## ⚠️ 注意事项

- **浏览器兼容性**：建议使用最新版本的 Chrome, Edge 或 Firefox 以获得最佳的 WebGL/Canvas 性能和 WebAssembly 支持。
- **性能要求**：由于需实时计算 3 万+ 粒子的物理状态及运行 AI 模型，建议在性能较好的 PC 或笔记本电脑上运行。移动设备可能会出现卡顿。
- **环境光线**：保持环境光线充足，有助于提高手势识别的准确率。
- **摄像头镜像**：为了符合照镜子的直觉习惯，预览画面已做水平镜像处理。

## 📄 许可证

本项目开源，供学习与交流使用。
